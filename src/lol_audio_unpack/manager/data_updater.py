# ğŸ Sparse is better than dense.
# ğŸ¼ ç¨€ç–ä¼˜äºç¨ å¯†
# @Author  : Virace
# @Email   : Virace@aliyun.com
# @Site    : x-item.com
# @Software: Pycharm
# @Create  : 2025/7/30 7:39
# @Update  : 2025/8/2 17:42
# @Detail  : æ•°æ®æ›´æ–°å™¨


import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any

from league_tools.formats import WAD
from loguru import logger

from lol_audio_unpack.manager.utils import (
    create_metadata_object,
    get_game_version,
    needs_update,
    read_data,
    write_data,
)
from lol_audio_unpack.utils.common import format_region, load_json
from lol_audio_unpack.utils.config import config
from lol_audio_unpack.utils.logging import performance_monitor
from lol_audio_unpack.utils.type_hints import StrPath


class DataUpdater:
    """
    è´Ÿè´£æ¸¸æˆæ•°æ®çš„æ›´æ–°å’Œå¤šè¯­è¨€JSONåˆå¹¶
    """

    def __init__(self, languages: list[str] | None = None, force_update: bool = False) -> None:
        """
        åˆå§‹åŒ–æ•°æ®æ›´æ–°å™¨

        :param languages: éœ€è¦å¤„ç†çš„è¯­è¨€åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬defaultï¼Œdefaultä¼šè‡ªåŠ¨æ·»åŠ ï¼‰ã€‚
                        å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨configä¸­çš„GAME_REGIONã€‚
        :param force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
        """
        self.game_path: Path = config.GAME_PATH
        self.manifest_path: Path = config.MANIFEST_PATH
        self.temp_path: Path = config.TEMP_PATH

        if not self.game_path or not self.manifest_path:
            raise ValueError("GAME_PATH å’Œ MANIFEST_PATH å¿…é¡»åœ¨é…ç½®ä¸­è®¾ç½®")

        if languages is None:
            game_region = config.GAME_REGION or "zh_CN"
            self.languages: list[str] = [game_region]
        else:
            self.languages: list[str] = languages

        self.version: str = get_game_version(self.game_path)
        self.version_manifest_path: Path = self.manifest_path / self.version
        self.data_file_base: Path = self.version_manifest_path / "data"
        self.process_languages: list[str] = self._prepare_language_list(self.languages)
        self.force_update = force_update

        self.version_manifest_path.mkdir(parents=True, exist_ok=True)

        # è®°å½•åˆå§‹åŒ–ä¿¡æ¯
        logger.debug(
            f"DataUpdater åˆå§‹åŒ–å®Œæˆ - ç‰ˆæœ¬: {self.version}, è¯­è¨€: {self.process_languages}, å¼ºåˆ¶æ›´æ–°: {force_update}"
        )

    def _prepare_language_list(self, languages: list[str]) -> list[str]:
        """å‡†å¤‡å¤„ç†è¯­è¨€åˆ—è¡¨ï¼Œç¡®ä¿defaultåœ¨åˆ—è¡¨ä¸­"""
        process_languages = ["default"]
        for lang in languages:
            if lang.lower() not in ["default", "en_us"]:
                process_languages.append(lang)
        return process_languages

    @staticmethod
    def _normalize_text(text: str) -> str:
        """æ ‡å‡†åŒ–æ–‡æœ¬"""
        if not isinstance(text, str):
            return text
        return text.replace("\u00a0", " ")

    @logger.catch
    @performance_monitor(threshold_ms=5000.0, level="INFO")
    def check_and_update(self) -> Path:
        """æ£€æŸ¥æ¸¸æˆç‰ˆæœ¬å¹¶æ›´æ–°æ•°æ®"""
        if not needs_update(self.data_file_base, self.version, self.force_update) and self._check_languages():
            logger.info(f"æ•°æ®æ–‡ä»¶å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ {self.version} ä¸”åŒ…å«æ‰€æœ‰è¯·æ±‚çš„è¯­è¨€ï¼Œæ— éœ€æ›´æ–°ã€‚")
            # è¿”å›åŸºç¡€è·¯å¾„ï¼Œè®©è°ƒç”¨è€…å†³å®šä½¿ç”¨å“ªä¸ªå…·ä½“æ–‡ä»¶
            return self.data_file_base

        run_temp_path = self.temp_path / f"update_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        run_temp_path.mkdir(parents=True, exist_ok=True)
        logger.debug(f"åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºè§£åŒ…: {run_temp_path}")

        try:
            self._process_data(run_temp_path)
            # æˆåŠŸåï¼Œæ—¥å¿—è®°å½•çš„æ˜¯ymlæˆ–msgpackçš„å®é™…è·¯å¾„
            fmt = "yml" if config.is_dev_mode() else "msgpack"
            logger.success(f"æ•°æ®æ›´æ–°å®Œæˆ: {self.data_file_base.with_suffix(f'.{fmt}')}")
            return self.data_file_base
        finally:
            if not config.is_dev_mode():
                try:
                    shutil.rmtree(run_temp_path)
                    logger.debug(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {run_temp_path}")
                except OSError:
                    # ä½¿ç”¨ç°ä»£çš„å¼‚å¸¸è®°å½•æ–¹å¼
                    logger.opt(exception=True).error(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {run_temp_path}")
            else:
                logger.warning(f"å¼€å‘æ¨¡å¼ï¼Œä¸´æ—¶ç›®å½•æœªåˆ é™¤: {run_temp_path}")

    def _check_languages(self) -> bool:
        """æ£€æŸ¥ç°æœ‰æ•°æ®æ–‡ä»¶æ˜¯å¦åŒ…å«æ‰€æœ‰è¯·æ±‚çš„è¯­è¨€"""
        data = read_data(self.data_file_base)
        if not data:
            return False

        existing_languages = set(data.get("languages", []))
        existing_languages.add("default")
        requested_languages = set(self.process_languages)

        if requested_languages.issubset(existing_languages):
            return True
        else:
            missing_langs = requested_languages - existing_languages
            logger.info(f"éœ€è¦æ›´æ–°æ•°æ®æ–‡ä»¶ï¼Œç¼ºå°‘è¯­è¨€: {missing_langs}")
            return False

    @performance_monitor(threshold_ms=10000.0, level="DEBUG")
    def _process_data(self, temp_path: Path) -> None:
        """å¤„ç†æ¸¸æˆæ•°æ®ï¼ŒåŒ…æ‹¬æå–ã€åˆå¹¶å’ŒéªŒè¯"""

        for language in self.process_languages:
            logger.info(f"æ­£åœ¨å¤„ç† {language} è¯­è¨€æ•°æ®...")
            self._extract_wad_data(temp_path, language)

        logger.info("åˆå¹¶å¤šè¯­è¨€æ•°æ®...")
        self._merge_and_build_data(temp_path)

        # ä»ä¸´æ—¶ç›®å½•å¤åˆ¶æœ€ç»ˆç”Ÿæˆçš„æ•°æ®æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
        temp_data_file_base = temp_path / self.version / "data"
        fmt = "yml" if config.is_dev_mode() else "msgpack"
        source_file = temp_data_file_base.with_suffix(f".{fmt}")

        if source_file.exists():
            self.version_manifest_path.mkdir(parents=True, exist_ok=True)
            shutil.copy2(source_file, self.data_file_base.with_suffix(f".{fmt}"))
            logger.debug(f"å·²å¤åˆ¶åˆå¹¶æ•°æ®åˆ°: {self.data_file_base.with_suffix(f'.{fmt}')}")
        else:
            raise FileNotFoundError(f"æœªèƒ½åˆ›å»ºåˆå¹¶æ•°æ®æ–‡ä»¶: {source_file}")

    def _load_language_json(self, base_path: Path, filename_template: str) -> dict[str, Any]:
        """åŠ è½½æŒ‡å®šæ¨¡æ¿çš„ã€æ‰€æœ‰è¯­è¨€çš„JSONæ–‡ä»¶"""
        loaded_data = {}
        logger.trace(f"åŠ è½½å¤šè¯­è¨€JSONæ–‡ä»¶æ¨¡æ¿: {filename_template}")

        for lang in self.process_languages:
            file_path = base_path / lang / filename_template.format(lang=lang)
            if file_path.exists():
                # è¿™é‡Œè¯»å–çš„æ˜¯WADè§£åŒ…å‡ºçš„åŸå§‹jsonï¼Œæ‰€ä»¥å¿…é¡»ç”¨load_json
                loaded_data[lang] = load_json(file_path)
                logger.trace(f"æˆåŠŸåŠ è½½ {lang} è¯­è¨€æ–‡ä»¶: {file_path}")
            else:
                logger.warning(f"æœªæ‰¾åˆ°JSONæ–‡ä»¶: {file_path}")

        logger.trace(f"å¤šè¯­è¨€JSONåŠ è½½å®Œæˆï¼Œå…± {len(loaded_data)} ç§è¯­è¨€")
        return loaded_data

    @logger.catch
    @performance_monitor(threshold_ms=8000.0, level="DEBUG")
    def _merge_and_build_data(self, temp_dir: Path) -> None:
        """èšåˆæ‰€æœ‰æ•°æ®å¤„ç†å’Œåˆå¹¶é€»è¾‘"""
        base_path = temp_dir / self.version

        summaries = self._load_language_json(base_path, "champion-summary.json")

        if "default" not in summaries:
            logger.error("æœªæ‰¾åˆ°defaultè¯­è¨€çš„è‹±é›„æ¦‚è¦æ•°æ®ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            return

        final_champions = {}

        # ä½¿ç”¨ lazy æ±‚å€¼è®°å½•è‹±é›„å¤„ç†ç»Ÿè®¡
        logger.opt(lazy=True).debug(
            "è‹±é›„æ•°æ®ç»Ÿè®¡: {champion_stats}",
            champion_stats=lambda: {
                "total_languages": len(summaries),
                "total_champions": len(summaries.get("default", [])),
                "language_breakdown": {lang: len(champions) for lang, champions in summaries.items()},
            },
        )

        for i, default_summary in enumerate(summaries["default"]):
            champ_id = str(default_summary["id"])
            if champ_id == "-1":
                continue

            alias = self._normalize_text(default_summary["alias"])
            details = self._load_language_json(base_path, f"champions/{champ_id}.json")
            default_details = details.get("default", {})

            # ä½¿ç”¨ TRACE çº§åˆ«è®°å½•æ¯ä¸ªè‹±é›„çš„å¤„ç†è¿›åº¦
            logger.trace(f"å¤„ç†è‹±é›„: {alias} (ID: {champ_id})")

            names = {lang: self._normalize_text(summ[i]["name"]) for lang, summ in summaries.items() if i < len(summ)}
            titles = {lang: self._normalize_text(det.get("title", "")) for lang, det in details.items()}
            descriptions = {
                lang: self._normalize_text(summ[i].get("description", ""))
                for lang, summ in summaries.items()
                if i < len(summ)
            }

            processed_skins = []
            for skin_idx, skin_detail in enumerate(default_details.get("skins", [])):
                skin_id_num = self._parse_skin_id(skin_detail["id"], int(champ_id))
                skin_names = {
                    lang: self._normalize_text(det.get("skins", [])[skin_idx].get("name", ""))
                    for lang, det in details.items()
                    if skin_idx < len(det.get("skins", []))
                }

                skin_data = {
                    "id": skin_detail["id"],
                    "isBase": skin_detail.get("isBase", False),
                    "skinNames": skin_names,
                    "binPath": f"data/characters/{alias}/skins/skin{skin_id_num}.bin",
                }

                processed_chromas = []
                for chroma_idx, chroma_detail in enumerate(skin_detail.get("chromas", [])):
                    chroma_id_num = self._parse_skin_id(chroma_detail["id"], int(champ_id))
                    chroma_names = {
                        lang: self._normalize_text(
                            det.get("skins", [])[skin_idx].get("chromas", [])[chroma_idx].get("name", "")
                        )
                        for lang, det in details.items()
                        if skin_idx < len(det.get("skins", []))
                        and chroma_idx < len(det.get("skins", [])[skin_idx].get("chromas", []))
                    }
                    processed_chromas.append(
                        {
                            "id": chroma_detail["id"],
                            "chromaNames": chroma_names,
                            "binPath": f"data/characters/{alias}/skins/skin{chroma_id_num}.bin",
                        }
                    )

                if processed_chromas:
                    skin_data["chromas"] = processed_chromas

                processed_skins.append(skin_data)

            final_champions[champ_id] = {
                "id": default_summary["id"],
                "alias": alias,
                "names": names,
                "titles": titles,
                "descriptions": {k: v for k, v in descriptions.items() if v},
                "skins": processed_skins,
                "wad": {
                    "root": f"Game/DATA/FINAL/Champions/{alias}.wad.client",
                    **{
                        lang: f"Game/DATA/FINAL/Champions/{alias}.{lang}.wad.client"
                        for lang in self.process_languages
                        if lang != "default"
                    },
                },
            }

        final_result = create_metadata_object(
            self.version, [lang for lang in self.process_languages if lang != "default"]
        )
        final_result["champions"] = final_champions

        # è®°å½•è‹±é›„å¤„ç†å®Œæˆç»Ÿè®¡
        logger.success(f"è‹±é›„æ•°æ®åˆå¹¶å®Œæˆï¼Œå…±å¤„ç† {len(final_champions)} ä¸ªè‹±é›„")

        logger.info("åˆå¹¶åœ°å›¾æ•°æ®...")
        maps_by_lang = self._load_language_json(base_path, "maps.json")
        if "default" in maps_by_lang:
            final_maps = {}
            map_id_to_index_per_lang = {
                lang: {m["id"]: i for i, m in enumerate(maps)} for lang, maps in maps_by_lang.items()
            }

            # ä½¿ç”¨ lazy æ±‚å€¼è®°å½•è¯¦ç»†çš„åœ°å›¾ç»Ÿè®¡ä¿¡æ¯
            logger.opt(lazy=True).debug(
                "åœ°å›¾æ•°æ®ç»Ÿè®¡: {map_stats}",
                map_stats=lambda: {
                    "total_languages": len(maps_by_lang),
                    "total_maps": len(maps_by_lang.get("default", [])),
                    "language_breakdown": {lang: len(maps) for lang, maps in maps_by_lang.items()},
                },
            )

            for default_map in maps_by_lang["default"]:
                map_id = default_map["id"]
                map_string_id = default_map["mapStringId"]

                names = {}
                for lang, maps in maps_by_lang.items():
                    if map_id in map_id_to_index_per_lang.get(lang, {}):
                        idx = map_id_to_index_per_lang[lang][map_id]
                        names[lang] = self._normalize_text(maps[idx]["name"])

                map_data = {"id": map_id, "mapStringId": map_string_id, "names": names}

                wad_prefix = f"Map{map_id}" if map_id != 0 else "Common"
                try:
                    relative_wad_path_base = config.GAME_MAPS_PATH.relative_to(self.game_path).as_posix()
                    wad_path_base = f"{relative_wad_path_base}/{wad_prefix}"
                    map_data["binPath"] = f"data/maps/shipping/{wad_prefix.lower()}/{wad_prefix.lower()}.bin"
                    wad_info = {
                        "root": f"{wad_path_base}.wad.client",
                        **{
                            lang: f"{wad_path_base}.{lang}.wad.client"
                            for lang in self.process_languages
                            if lang != "default"
                        },
                    }
                    if (self.game_path / wad_info["root"]).exists():
                        map_data["wad"] = wad_info
                    else:
                        logger.warning(
                            f"åœ°å›¾ {wad_prefix} çš„WADæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡: {self.game_path / wad_info['root']}"
                        )
                except ValueError:
                    logger.error("GAME_MAPS_PATH é…ç½®ä¼¼ä¹ä¸æ­£ç¡®ï¼Œæ— æ³•ç”Ÿæˆç›¸å¯¹è·¯å¾„ã€‚")

                final_maps[str(map_id)] = map_data
            final_result["maps"] = final_maps

            # è®°å½•åœ°å›¾å¤„ç†å®Œæˆç»Ÿè®¡
            logger.success(f"åœ°å›¾æ•°æ®åˆå¹¶å®Œæˆï¼Œå…±å¤„ç† {len(final_maps)} ä¸ªåœ°å›¾")
        else:
            logger.warning("æœªæ‰¾åˆ°defaultè¯­è¨€çš„åœ°å›¾æ•°æ®ï¼Œè·³è¿‡å¤„ç†ã€‚")

        # æ ¹æ®ç¯å¢ƒå†™å…¥æœ€ä½³æ ¼å¼
        write_data(final_result, base_path / "data")

        # è®°å½•æœ€ç»ˆå¤„ç†å®Œæˆç»Ÿè®¡
        logger.success(
            f"æ•°æ®åˆå¹¶å®Œæˆ - è‹±é›„: {len(final_result.get('champions', {}))}, "
            f"åœ°å›¾: {len(final_result.get('maps', {}))}, "
            f"è¯­è¨€: {len(self.process_languages)}"
        )

    @performance_monitor(threshold_ms=3000.0, level="DEBUG")
    def _extract_wad_data(self, out_dir: StrPath, region: str) -> None:
        """ä»WADæ–‡ä»¶æå–JSONæ•°æ®"""
        out_path = Path(out_dir) / self.version / region
        out_path.mkdir(parents=True, exist_ok=True)
        _region = "default" if region.lower() == "en_us" else region
        _head = format_region(_region)

        if _head == "default":
            wad_files = list(self.game_path.glob("LeagueClient/Plugins/rcp-be-lol-game-data/default-assets*.wad"))
        else:
            wad_files = [self.game_path / "LeagueClient" / "Plugins" / f"rcp-be-lol-game-data/{_head}-assets.wad"]

        if not wad_files or not all(f.exists() for f in wad_files):
            logger.error(f"æœªæ‰¾åˆ° {_region} åŒºåŸŸçš„WADæ–‡ä»¶")
            return

        logger.debug(f"æ‰¾åˆ° {len(wad_files)} ä¸ªWADæ–‡ä»¶éœ€è¦å¤„ç†")
        hash_table = [
            f"plugins/rcp-be-lol-game-data/global/{_region}/v1/champion-summary.json",
            f"plugins/rcp-be-lol-game-data/global/{_region}/v1/maps.json",
        ]

        def output_file_name(path: str) -> Path:
            # ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…æ›´é€šç”¨çš„è·¯å¾„
            reg = re.compile(rf"plugins/rcp-be-lol-game-data/global/{_region}/v\d+/", re.IGNORECASE)
            new = reg.sub("", path)
            return out_path / new

        # æå–åŸºç¡€æ•°æ®æ–‡ä»¶
        logger.debug(f"å¼€å§‹æå–åŸºç¡€æ•°æ®æ–‡ä»¶ï¼Œå…± {len(hash_table)} ä¸ªç›®æ ‡æ–‡ä»¶")
        for wad_file in wad_files:
            logger.trace(f"ä»WADæ–‡ä»¶æå–: {wad_file.name}")
            WAD(wad_file).extract(hash_table, output_file_name)

        # æå–è‹±é›„è¯¦ç»†ä¿¡æ¯
        summary_file = out_path / "champion-summary.json"
        if summary_file.exists():
            try:
                champions = load_json(summary_file)
                champion_hashes = [
                    f"plugins/rcp-be-lol-game-data/global/{_region}/v1/champions/{item['id']}.json"
                    for item in champions
                    if item["id"] != -1
                ]

                logger.debug(f"å‡†å¤‡æå– {len(champion_hashes)} ä¸ªè‹±é›„è¯¦ç»†ä¿¡æ¯")
                (out_path / "champions").mkdir(exist_ok=True)

                for wad_file in wad_files:
                    logger.trace(f"ä» {wad_file.name} æå–è‹±é›„è¯¦ç»†ä¿¡æ¯")
                    WAD(wad_file).extract(champion_hashes, output_file_name)

                logger.success(f"è‹±é›„ä¿¡æ¯æå–å®Œæˆï¼Œå…± {len(champion_hashes)} ä¸ªè‹±é›„")
            except Exception:
                logger.opt(exception=True).error(f"è§£åŒ… {_region} åŒºåŸŸè‹±é›„ä¿¡æ¯æ—¶å‡ºé”™")
                if config.is_dev_mode():
                    raise
        else:
            logger.warning("æœªæ‰¾åˆ°è‹±é›„æ¦‚è¦æ–‡ä»¶ï¼Œè·³è¿‡è‹±é›„è¯¦ç»†ä¿¡æ¯æå–")

    def _parse_skin_id(self, full_id: int, champion_id: int) -> int:
        """ä»å®Œæ•´çš„çš®è‚¤IDä¸­æå–çš®è‚¤ç¼–å·"""
        champion_id_len = len(str(champion_id))
        skin_id_str = str(full_id)[champion_id_len:]
        return int(skin_id_str)
